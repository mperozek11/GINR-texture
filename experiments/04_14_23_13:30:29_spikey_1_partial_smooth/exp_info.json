{"model": "MLP(\n  (model): ModuleList(\n    (0): Linear(in_features=100, out_features=512, bias=True)\n    (1): Sine()\n    (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (3): Linear(in_features=512, out_features=512, bias=True)\n    (4): Sine()\n    (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (6): Linear(in_features=512, out_features=512, bias=True)\n    (7): Sine()\n    (8): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (9): Linear(in_features=612, out_features=512, bias=True)\n    (10): Sine()\n    (11): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (12): Linear(in_features=512, out_features=512, bias=True)\n    (13): Sine()\n    (14): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (15): Linear(in_features=512, out_features=3, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "loss_fn": "MSELoss()", "epochs": 5, "rand_inits": 2, "rand_seed": 11, "test": "TEST!!", "best_rand_init": 1, "train_results": [{"run": 0, "best_loss": 0.15312951803207397, "train_losses": [0.8610091853786159, 0.6134305902429529, 0.4243099625046189, 0.2811847635217615, 0.18323632833119985], "eval_losses": [0.7622642517089844, 0.5153560638427734, 0.32926833629608154, 0.22477203607559204, 0.15312951803207397]}, {"run": 1, "best_loss": 0.006533685605973005, "train_losses": [0.11276803145537505, 0.06422752947420687, 0.037688364853730075, 0.02309188327273807, 0.01258027392464715], "eval_losses": [0.0926322191953659, 0.04565924406051636, 0.031814079731702805, 0.019330235198140144, 0.006533685605973005]}]}