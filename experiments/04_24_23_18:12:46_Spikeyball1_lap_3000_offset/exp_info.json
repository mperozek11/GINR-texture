{"model": "MLP(\n  (model): ModuleList(\n    (0): Linear(in_features=100, out_features=512, bias=True)\n    (1): Sine()\n    (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (3): Linear(in_features=512, out_features=512, bias=True)\n    (4): Sine()\n    (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (6): Linear(in_features=512, out_features=512, bias=True)\n    (7): Sine()\n    (8): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (9): Linear(in_features=612, out_features=512, bias=True)\n    (10): Sine()\n    (11): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (12): Linear(in_features=512, out_features=512, bias=True)\n    (13): Sine()\n    (14): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (15): Linear(in_features=512, out_features=3, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: False\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "loss_fn": "MSELoss()", "epochs": 20, "rand_inits": 2, "rand_seed": 11, "experiment notes": "first surface norms experiment", "best_rand_init": 1, "train_results": [{"run": 0, "best_loss": 0.002121938392519951, "train_losses": [0.8604885307518212, 0.6162980053875897, 0.4233171359912769, 0.28297965591018265, 0.18685139836491765, 0.11326369723758183, 0.06787963815637536, 0.042862827713425096, 0.021947619077321644, 0.01562654972076416, 0.006801752625284968, 0.004235451688637605, 0.003037900135323808, 0.0022931620478630066, 0.0021463960811898514, 0.0018874654496038282, 0.0019584787455764977, 0.001826110723856333, 0.0019489285108205434, 0.0018709740928701452], "eval_losses": [0.7257386445999146, 0.49052125215530396, 0.2890383303165436, 0.23571105301380157, 0.1966800093650818, 0.1148366630077362, 0.04871278256177902, 0.028129056096076965, 0.03983338549733162, 0.009015345014631748, 0.0016469964757561684, 0.0028687622398138046, 0.0011947464663535357, 0.00266720331273973, 0.0010990235023200512, 0.0013597487704828382, 0.0011010480811819434, 0.003160880645737052, 0.0016496452735736966, 0.002121938392519951]}, {"run": 1, "best_loss": 0.0030349448788911104, "train_losses": [0.7734091990702862, 0.3310009208885399, 0.14866687156058647, 0.05729623743005701, 0.027542413891972723, 0.011458909189378893, 0.0073151709260167305, 0.004560249077307212, 0.0027669140615978758, 0.003588259220123291, 0.0031636623111931054, 0.0031307249053104504, 0.0035722767179076735, 0.0036766404235685194, 0.0024483453583072972, 0.002545093563762871, 0.002482449686205065, 0.0029877158435615333, 0.003108880407101399, 0.0027636253350489847], "eval_losses": [0.4559217393398285, 0.19821590185165405, 0.09681008756160736, 0.03247580677270889, 0.013879216276109219, 0.0044678328558802605, 0.0013003569329157472, 0.007339216768741608, 0.0028657999355345964, 0.006154774222522974, 0.0011480603134259582, 0.0011570038041099906, 0.0034875436685979366, 0.002543168608099222, 0.0021980220917612314, 0.0026859533973038197, 0.005441192537546158, 0.002230330603197217, 0.0013936411123722792, 0.0030349448788911104]}]}