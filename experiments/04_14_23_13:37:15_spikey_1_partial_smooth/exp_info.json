{"model": "MLP(\n  (model): ModuleList(\n    (0): Linear(in_features=100, out_features=512, bias=True)\n    (1): Sine()\n    (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (3): Linear(in_features=512, out_features=512, bias=True)\n    (4): Sine()\n    (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (6): Linear(in_features=512, out_features=512, bias=True)\n    (7): Sine()\n    (8): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (9): Linear(in_features=612, out_features=512, bias=True)\n    (10): Sine()\n    (11): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (12): Linear(in_features=512, out_features=512, bias=True)\n    (13): Sine()\n    (14): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (15): Linear(in_features=512, out_features=3, bias=True)\n  )\n)", "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)", "loss_fn": "MSELoss()", "epochs": 5, "rand_inits": 3, "rand_seed": 11, "test": "TEST!!", "best_rand_init": 2, "train_results": [{"run": 0, "best_loss": 0.13365516066551208, "train_losses": [0.86609309428447, 0.616282437298749, 0.4235406308560758, 0.2837601996756889, 0.18681807131380648], "eval_losses": [0.7198881506919861, 0.4875236749649048, 0.36306148767471313, 0.2743307650089264, 0.13365516066551208]}, {"run": 1, "best_loss": 0.07601739466190338, "train_losses": [0.8503258163864548, 0.5527190131110113, 0.3539682594505516, 0.22705106477479678, 0.14616794843931455], "eval_losses": [0.689596951007843, 0.4025322496891022, 0.2809543013572693, 0.16334953904151917, 0.07601739466190338]}, {"run": 2, "best_loss": 0.13554923236370087, "train_losses": [0.8510825182940509, 0.5547616288468644, 0.334653106895653, 0.21536471392657305, 0.1314015646238585], "eval_losses": [0.6367077231407166, 0.4177759885787964, 0.31212854385375977, 0.14766594767570496, 0.13554923236370087]}]}